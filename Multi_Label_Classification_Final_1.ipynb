{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a894ad8b-0691-4133-9dcf-f125dece1214",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing dependencies\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6d55a0d-c22a-4fa8-ae0e-de04cca7d25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess images\n",
    "def preprocess_image(image):\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [224, 224])\n",
    "    image = image / 255.0\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b98b587-3bd5-47e9-ba14-b2898ae5a9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load and preprocess images\n",
    "def load_and_preprocess_image(file_path):\n",
    "    image = tf.io.read_file(file_path)\n",
    "    return preprocess_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fff17f7c-7ef8-4663-8ea8-7ed6111baf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to combine genres for each image\n",
    "def combine_labels(data):\n",
    "    combined_data = {}\n",
    "    for _, row in data.iterrows():\n",
    "        image_name = row['Image name']\n",
    "        genre = row['Genre']\n",
    "        if image_name in combined_data:\n",
    "            combined_data[image_name].add(genre)\n",
    "        else:\n",
    "            combined_data[image_name] = {genre}\n",
    "    return combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e57f525-abc0-4cfc-adfa-87ff81b654d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load data from master folder (Train)\n",
    "def load_data_from_master_folder(master_folder, image_dir, num_classes):\n",
    "    csv_files = [os.path.join(master_folder, f) for f in os.listdir(master_folder) if f.endswith('.csv')]\n",
    "    datasets = []\n",
    "\n",
    "    # Initialize genre mapping dictionary\n",
    "    genre_mapping = {}\n",
    "    idx = 0\n",
    "\n",
    "    # Update genre mapping if genre is not already mapped\n",
    "    for csv_file in csv_files:\n",
    "        df = pd.read_csv(csv_file)\n",
    "        for genre in df['Genre'].unique():\n",
    "            if genre not in genre_mapping:\n",
    "                genre_mapping[genre] = idx\n",
    "                idx += 1\n",
    "\n",
    "    for csv_file in csv_files:\n",
    "        df = pd.read_csv(csv_file)\n",
    "        combined_data = combine_labels(df)\n",
    "        file_paths_labels = {}\n",
    "\n",
    "        # Create file paths and multi-hot encoded labels\n",
    "        for image_name, genres in combined_data.items():\n",
    "            genre_list = list(genres)\n",
    "            file_path = os.path.join(image_dir, genre_list[0], image_name)\n",
    "            if file_path not in file_paths_labels:\n",
    "                file_paths_labels[file_path] = np.zeros(num_classes)\n",
    "            for genre in genres:\n",
    "                file_paths_labels[file_path][genre_mapping[genre]] = 1\n",
    "\n",
    "        # Convert file paths and labels to lists\n",
    "        file_paths = list(file_paths_labels.keys())\n",
    "        labels = np.array(list(file_paths_labels.values()))\n",
    "\n",
    "        # Create TensorFlow dataset\n",
    "        path_ds = tf.data.Dataset.from_tensor_slices(file_paths)\n",
    "        image_ds = path_ds.map(load_and_preprocess_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "        label_ds = tf.data.Dataset.from_tensor_slices(labels.astype('float32'))\n",
    "        dataset = tf.data.Dataset.zip((image_ds, label_ds)).batch(32).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "        datasets.append(dataset)\n",
    "\n",
    "    return datasets, len(csv_files), genre_mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f0d3156-f969-4ef5-8db5-9743ac55f32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load data from master folder (Validation and Test)\n",
    "def load_data_with_existing_genre_mapping(master_folder, image_dir, num_classes, genre_mapping):\n",
    "    csv_files = [os.path.join(master_folder, f) for f in os.listdir(master_folder) if f.endswith('.csv')]\n",
    "    datasets = []\n",
    "\n",
    "    for csv_file in csv_files:\n",
    "        df = pd.read_csv(csv_file)\n",
    "        combined_data = combine_labels(df)\n",
    "        file_paths_labels = {}\n",
    "\n",
    "        for image_name, genres in combined_data.items():\n",
    "            genre_list = list(genres)\n",
    "            file_path = os.path.join(image_dir, genre_list[0], image_name)\n",
    "            if file_path not in file_paths_labels:\n",
    "                file_paths_labels[file_path] = np.zeros(num_classes)\n",
    "            for genre in genres:\n",
    "                if genre in genre_mapping:\n",
    "                    file_paths_labels[file_path][genre_mapping[genre]] = 1\n",
    "\n",
    "        file_paths = list(file_paths_labels.keys())\n",
    "        labels = np.array(list(file_paths_labels.values()))\n",
    "\n",
    "        path_ds = tf.data.Dataset.from_tensor_slices(file_paths)\n",
    "        image_ds = path_ds.map(load_and_preprocess_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "        label_ds = tf.data.Dataset.from_tensor_slices(labels.astype('float32'))\n",
    "        dataset = tf.data.Dataset.zip((image_ds, label_ds)).batch(32).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "        datasets.append(dataset)\n",
    "\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9727d9be-cac8-41bb-9cea-124e4452b4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN Architecture (Think about adding batch normalization)\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "\n",
    "def create_model(input_shape, num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=16, kernel_size=(5, 5), activation=\"relu\", input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # model.add(Dropout(0.25))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(filters=32, kernel_size=(5, 5), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(filters=64, kernel_size=(5, 5), activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # model.add(Dropout(0.25))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(filters=64, kernel_size=(5, 5), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    # model.add(Dropout(0.5))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    # model.add(Dropout(0.25))\n",
    "    model.add(Dense(num_classes, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62095b94-7d0e-4557-995b-908b198c2038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN Architecture (Think about adding batch normalization)\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=16, kernel_size=(5, 5), activation=\"relu\", input_shape=(224,224,3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.25))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=32, kernel_size=(5, 5), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=64, kernel_size=(5, 5), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.25))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=64, kernel_size=(5, 5), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "# model.add(Dropout(0.25))\n",
    "model.add(Dense(20, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65c126a1-48b5-4e99-bd05-9604ec5be189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 220, 220, 16)      1216      \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 110, 110, 16)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 110, 110, 16)     64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 106, 106, 32)      12832     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 53, 53, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 53, 53, 32)        0         \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 53, 53, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 49, 49, 64)        51264     \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 24, 24, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 24, 24, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 20, 20, 64)        102464    \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 10, 10, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 10, 10, 64)        0         \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 10, 10, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 6400)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               819328    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 20)                1300      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 997,364\n",
      "Trainable params: 997,012\n",
      "Non-trainable params: 352\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a41bd20a-740b-43a6-a4ba-0408f464f020",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mplot_model\u001b[49m(model, to_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel.png\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plot_model' is not defined"
     ]
    }
   ],
   "source": [
    "plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9745cf86-7353-4c55-ab0e-13ca12060019",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enhancement of cluster structuring\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def neighbor_discriminant_term(features, labels, k):\n",
    "    features_np = features.numpy()\n",
    "    labels_np = labels.numpy()\n",
    "\n",
    "    # Dynamically set k_neighbors based on available samples\n",
    "    num_samples = features_np.shape[0]\n",
    "    k_neighbors = min(k, num_samples - 1)\n",
    "    \n",
    "    if k_neighbors < 1:\n",
    "        return 0.0\n",
    "\n",
    "    # Calculate pairwise distances\n",
    "    nbrs = NearestNeighbors(n_neighbors=k_neighbors+1, algorithm='auto').fit(features_np)\n",
    "    distances, indices = nbrs.kneighbors(features_np)\n",
    "\n",
    "    discriminant_loss = 0.0\n",
    "\n",
    "    for i, neighbors in enumerate(indices):\n",
    "        # Skip the first neighbor since it's the point itself\n",
    "        neighbors = neighbors[1:]\n",
    "        same_label_count = 0\n",
    "        diff_label_count = 0\n",
    "\n",
    "        for neighbor in neighbors:\n",
    "            if np.array_equal(labels_np[i], labels_np[neighbor]):\n",
    "                same_label_count += 1\n",
    "            else:\n",
    "                diff_label_count += 1\n",
    "        \n",
    "        if same_label_count + diff_label_count > 0:\n",
    "            discriminant_loss += diff_label_count / (same_label_count + diff_label_count)\n",
    "\n",
    "    return discriminant_loss / num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c395d23-4833-45d1-80f4-6dc2a34f774b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated correlation_loss function to include necessary arguments (Encourages selection of complementary features)\n",
    "def correlation_loss(models, lambda_weight, images, labels, loss_fn):\n",
    "    total_loss = 0.0\n",
    "    num_models = len(models)\n",
    "    for i in range(num_models):\n",
    "        for j in range(i + 1, num_models):\n",
    "            with tf.GradientTape() as tape_i:\n",
    "                predictions_i = models[i](images, training=True)\n",
    "                loss_i = loss_fn(labels, predictions_i)\n",
    "            gradients_i = tape_i.gradient(loss_i, models[i].trainable_variables)\n",
    "            \n",
    "            with tf.GradientTape() as tape_j:\n",
    "                predictions_j = models[j](images, training=True)\n",
    "                loss_j = loss_fn(labels, predictions_j)\n",
    "            gradients_j = tape_j.gradient(loss_j, models[j].trainable_variables)\n",
    "            \n",
    "            dot_product = tf.reduce_sum([tf.reduce_sum(tf.multiply(grad_i, grad_j)) for grad_i, grad_j in zip(gradients_i, gradients_j)])\n",
    "            norm_i = tf.reduce_sum([tf.norm(grad_i) for grad_i in gradients_i])\n",
    "            norm_j = tf.reduce_sum([tf.norm(grad_j) for grad_j in gradients_j])\n",
    "            \n",
    "            correlation = dot_product / (norm_i * norm_j + 1e-8)\n",
    "            total_loss += correlation\n",
    "    return lambda_weight * total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbb8d37b-4f51-4ba8-add5-6068d2a76727",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (224, 224, 3)\n",
    "num_epochs = 10\n",
    "all_models = []\n",
    "lambda_weight = 0.001\n",
    "k_neighbors = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "262963a9-13de-4eda-aa6a-1e1860779b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Train data\n",
    "master_directory = \"/home/prolay/Desktop/Kartavya Desai/Folder_For_DFS\"\n",
    "image_master_directory = '/home/prolay/Desktop/Kartavya Desai/Augmented image_two_three/Train_TwoThree_Aug'\n",
    "num_classes = 20  # Adjust this number based on the total number of unique genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0417a483-f5b6-46ab-b6cb-dea40c5e58a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets, num_subsets, genre_mapping = load_data_from_master_folder(master_directory, image_master_directory, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60356193-5fa8-484d-ab7e-01618723c8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Validation data\n",
    "validation_master_directory = '/home/prolay/Desktop/Kartavya Desai/Validation CSV'\n",
    "validation_image_master_directory = '/home/prolay/Desktop/Kartavya Desai/Augmented image_two_three/Val_TwoThree_Aug'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "125a2571-96a8-4861-b192-912ba29da03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_datasets = load_data_with_existing_genre_mapping(validation_master_directory, validation_image_master_directory, num_classes, genre_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54a85d68-e44b-4e44-8bc9-c5c364801761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "\n",
    "# # Callbacks for storing training logs and checkpoints\n",
    "# checkpoint_dir = \"./checkpoints\"\n",
    "# os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "# checkpoint_callback = ModelCheckpoint(\n",
    "#     filepath=os.path.join(checkpoint_dir, \"model_epoch_{epoch:02d}_val_acc_{val_accuracy:.2f}.h5\"),\n",
    "#     save_best_only=True,\n",
    "#     monitor='val_accuracy',\n",
    "#     mode='max',\n",
    "#     verbose=1\n",
    "# )\n",
    "# csv_logger = CSVLogger('training_log.csv', append=True)\n",
    "\n",
    "# # Prepare the list of callbacks\n",
    "# callbacks = [checkpoint_callback, csv_logger]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03014dbf-8423-405e-9a38-ab8fc6d04849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on subset 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-08 09:53:18.288883: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.8084489107131958, Accuracy: 0.9123438596725464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-08 09:54:13.938304: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.7532879114151001, Validation Accuracy: 0.8940645456314087\n"
     ]
    }
   ],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import tensorflow as tf\n",
    "# import numpy as np\n",
    "\n",
    "# Initialize lists to store metrics\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "# Training loop with shared weights, correlation loss, and validation accuracy\n",
    "for i, dataset in enumerate(datasets):\n",
    "    print(f\"Training on subset {i+1}/{num_subsets}\")\n",
    "    \n",
    "    model = create_model(input_shape, num_classes)\n",
    "    if i > 0:\n",
    "        model.set_weights(all_models[-1].get_weights())\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "    loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "        train_accuracy = tf.keras.metrics.BinaryAccuracy()\n",
    "\n",
    "        # Training step\n",
    "        for images, labels in dataset:\n",
    "            with tf.GradientTape() as tape:\n",
    "                predictions = model(images, training=True)\n",
    "                loss_value = loss_fn(labels, predictions)\n",
    "                if len(all_models) > 0:\n",
    "                    loss_value += correlation_loss(all_models, lambda_weight, images, labels, loss_fn)\n",
    "                \n",
    "                # Neighbor-based discriminant term\n",
    "                features = model(images, training=False)\n",
    "                discriminant_loss = neighbor_discriminant_term(features, labels, k_neighbors)\n",
    "                total_loss = loss_value + discriminant_loss\n",
    "\n",
    "            gradients = tape.gradient(total_loss, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "            epoch_loss_avg.update_state(total_loss)\n",
    "            train_accuracy.update_state(labels, predictions)\n",
    "\n",
    "        # Record training loss and accuracy\n",
    "        train_losses.append(epoch_loss_avg.result())\n",
    "        train_accuracies.append(train_accuracy.result())\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}, Loss: {epoch_loss_avg.result()}, Accuracy: {train_accuracy.result()}\")\n",
    "\n",
    "        # Validation step\n",
    "        val_loss_avg = tf.keras.metrics.Mean()\n",
    "        val_accuracy = tf.keras.metrics.BinaryAccuracy()\n",
    "        for val_images, val_labels in val_datasets[i]:\n",
    "            val_predictions = model(val_images, training=False)\n",
    "            val_loss = loss_fn(val_labels, val_predictions)\n",
    "            val_loss_avg.update_state(val_loss)\n",
    "            val_accuracy.update_state(val_labels, val_predictions)\n",
    "\n",
    "        # Record validation loss and accuracy\n",
    "        val_losses.append(val_loss_avg.result())\n",
    "        val_accuracies.append(val_accuracy.result())\n",
    "\n",
    "        print(f\"Validation Loss: {val_loss_avg.result()}, Validation Accuracy: {val_accuracy.result()}\")\n",
    "\n",
    "    all_models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a59611f-98ce-4b9e-8003-e10a36fe9bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = all_models[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f026b5e8-5503-4f61-8941-7b1f13f00269",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model.save(\"completed_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89906cfd-b64f-4538-be77-c722b9b99fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "test_master_directory = '/home/prolay/Desktop/Kartavya Desai/Test_DFS'\n",
    "test_image_master_directory = \"/home/prolay/Desktop/Kartavya Desai/Augmented image_two_three/Test_TwoThree_Aug\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80089e1-509f-4122-8519-04b1b628761b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datasets = load_data_with_existing_genre_mapping(test_master_directory, test_image_master_directory, num_classes, genre_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11de4590-ec32-4d8e-b496-1b2e7446fb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Evaluation Function\n",
    "from sklearn.metrics import hamming_loss, accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "def evaluate_model(model, test_dataset):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    for images, labels in test_dataset:\n",
    "        predictions = model.predict(images)\n",
    "        y_true.extend(labels.numpy())\n",
    "        y_pred.extend((predictions > 0.18).astype(int))\n",
    "\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    print(y_true.shape)\n",
    "    print(y_pred.shape)\n",
    "    print(y_true[:5])\n",
    "    print(y_pred[:5])\n",
    "    h_loss = hamming_loss(y_true, y_pred)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average='micro')\n",
    "    precision = precision_score(y_true, y_pred, average='micro')\n",
    "    recall = recall_score(y_true, y_pred, average='micro')\n",
    "\n",
    "    print(f\"Hamming Loss: {h_loss}\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"F1 Score: {f1}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "\n",
    "    return h_loss, accuracy, f1, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ec0b2e-61a8-4a98-b3d8-f4b89f7b9b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation of all the subset.\n",
    "for i in range(len(test_datasets)):\n",
    "    evaluate_model(final_model, test_datasets[i])\n",
    "  # Evaluating on the first subset of the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fe20f6-635b-4c79-859b-0ecc0ae72073",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
